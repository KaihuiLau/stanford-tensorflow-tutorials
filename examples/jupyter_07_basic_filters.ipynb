{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Neural Network (CNN) - basic filters\n",
    "\n",
    "Author: Chip Huyen\n",
    "\n",
    "Jupyter scribe: Jiageng Liu\n",
    "\n",
    "Prepared for the class CS 20SI: \"TensorFlow for Deep Learning Research\"\n",
    "\n",
    "[https://cs20si.stanford.edu](cs20si.stanford.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple examples of convolution to do some basic filters. Also demonstrates the use of TensorFlow data readers.<br>\n",
    "\n",
    "We will use some popular filters for our image. It seems to be working with grayscale images, but not with rgb images. It's probably because I didn't choose the right kernels for rgb images.<br>\n",
    "\n",
    "- kernels for rgb images have dimensions 3 x 3 x 3 x 3\n",
    "- kernels for grayscale images have dimensions 3 x 3 x 1 x 1\n",
    "\n",
    "_Note_:\n",
    "When you call tf.train.string_input_producer, a tf.train.QueueRunner is added to the graph, which must be run using e.g. tf.train.start_queue_runners() else your session will run into deadlock and your program will crash.<br>\n",
    "\n",
    "And to run QueueRunner, you need a coordinator to close to your queue for you. Without coordinator, your threads will keep on running outside session and you will have the error: _ERROR:tensorflow:Exception in QueueRunner: Attempted to use a closed Session_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from matplotlib import gridspec as gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import kernels\n",
    "\n",
    "FILENAME = 'data/friday.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read one image into TF\n",
    "\n",
    "For demostration only. Easier to use Pillow in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename_queue = tf.train.string_input_producer([FILENAME])\n",
    "image_reader = tf.WholeFileReader()\n",
    "_, image_file = image_reader.read(filename_queue)\n",
    "image = tf.image.decode_jpeg(image_file, channels=3)\n",
    "image = tf.cast(image, tf.float32) / 256.0 # cast to float to make conv2d work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolve filter with the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparation: make grayscale and batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = tf.image.rgb_to_grayscale(image)\n",
    "image = tf.expand_dims(image, 0)  # make it into a batch of 1 element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some constants. See lecture for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernels = [kernels.BLUR_FILTER, kernels.SHARPEN_FILTER, kernels.EDGE_FILTER, \n",
    "                    kernels.TOP_SOBEL, kernels.EMBOSS_FILTER]\n",
    "strides = [1, 3, 3, 1]\n",
    "padding = 'SAME'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolve with various filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = [image[0]]\n",
    "for i, kernel in enumerate(kernels):\n",
    "    filtered_image = tf.nn.conv2d(image, kernel, strides=strides, padding=padding)[0]\n",
    "    if i == 2:\n",
    "        filtered_image = tf.minimum(tf.nn.relu(filtered_image), 255)\n",
    "    images.append(filtered_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    images = sess.run(images)\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs = gridspec.GridSpec(1, len(images))\n",
    "for i, image in enumerate(images):\n",
    "    plt.subplot(gs[0, i])\n",
    "    image = image.reshape(image.shape[0], image.shape[1])\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-gpu]",
   "language": "python",
   "name": "conda-env-tensorflow-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
